{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing simple things and creating function for the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random \n",
    "import collections\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def elapsed(sec):\n",
    "    if sec<60:\n",
    "        return str(sec) + \" sec\"\n",
    "    elif sec<(60*60):\n",
    "        return str(sec/60) + \" min\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had many problems in this, paths should be defined as './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = 'tensorflow/logs'\n",
    "writer = tf.summary.FileWriter(log_path)\n",
    "training_file = 'input/paragraph.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As training_file contains the text file, it is preprocessed.\n",
    "1. content contains the lines of the paragraph\n",
    "2. strip() in-built function of Python is used to remove all the leading and trailing spaces from a string.\n",
    "   eg. \"   geeks for geeks\" split() this we will beg \"geeks for geeks\"\n",
    "3. split() method returns a list of strings after breaking the given string by the specified separator.\n",
    "4. added the content to the numpy array\n",
    "5. what the reshape([-1,]) does is whatever the dimension of the content is, it converts it into any possible value replacing -1, here 12 replaces -1 satisfying total 12 elements. if reshape([-1, 2]) then -1 would be 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data....\n"
     ]
    }
   ],
   "source": [
    "def read_data(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    content = [content[i].split() for i in range(len(content))]\n",
    "    content = np.array(content)\n",
    "    content = np.reshape(content, [-1, ])\n",
    "    return content\n",
    "\n",
    "training_data = read_data(training_file)\n",
    "print(\"Loaded training data....\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important requirement of the RNN is dictionary,\n",
    "one which maps word to value, and another one reverse of it.\n",
    "1. Counter(words) creates a dictonary which contains the words as key and frequency as value\n",
    "2. word -> key, _ -> value\n",
    "3. we are making a dictionary and giving word a value which is unique.\n",
    "4. reverse dictionary for reversing the things back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary\n",
    "\n",
    "dictionary, reverse_dictionary = build_dataset(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are defining stuff.\n",
    "1. vocab_size: our length of knowledge about words\n",
    "2. input of 3 words\n",
    "3. total hidden layer nodes: 512\n",
    "4. X, Y are our tensorflow variables, input layer, output layer.\n",
    "5. I had a slight issue ahead because of graphs of tensorflow, make sure you reset them.\n",
    "\n",
    "Tensorflow Variables:\n",
    "1. tf.placeholder(\"float\", [None, n_input, 1] this tells -> \"I dont know the number of rows but I know one row should have a shape of (n_input, 1)\"\n",
    "2. eg for images: (None, 128, 128, 3) -> \"I dont know the rows but each row should be of (128,128,3) shape.\n",
    "\n",
    "Note:\n",
    "1. Our output y is of vocab size that is it will be of 112 words vector.\n",
    "2. We will use one hot encoding using this vector as a output vector\n",
    "3. input will be of 3 words i.e. 3 words from the training set will be chosen and feed to the RNN which goes on computing the sequence and for the accuracy what we want is the last output of the RNN, now point to be noted, which frustrated me the most when I was learning this during btp is that,\n",
    "    1. the output of the RNN is h(t) which is a hidden layer of 512, now we need to know what word it indicates.. \n",
    "    2. here comes the output nodes and biases,\n",
    "    3. y = (h(t).weights['out]) + biases['out']\n",
    "    4. and this will be \n",
    "    5. here y will be a 112 vector.\n",
    "    \n",
    " \n",
    "\n",
    "<img src=\"LSTM.jpg\" style=\"width: 500px; float: left; height: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(dictionary)\n",
    "learning_rate = 1e-3\n",
    "training_iters = 50000\n",
    "display_step = 5000\n",
    "n_input = 3\n",
    "n_hidden = 512\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "y = tf.placeholder(\"float\", [None, vocab_size])\n",
    "\n",
    "#RNN output node weights and biases\n",
    "weights = {\n",
    "    'out' : tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "}\n",
    "biases = {\n",
    "    'out' : tf.Variable(tf.random_normal([vocab_size]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "    #reshape to [1, n_input]\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "    x = tf.split(x, n_input, 1)\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.GRUCell(n_hidden), rnn.GRUCell(n_hidden)])\n",
    "    \n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype = tf.float32)\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = RNN(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-e5ccb7be686b>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1003/50000 [00:40<32:37, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 1000, Average loss= 6.020145, Average Accuracy= 6.10%\n",
      "['at', 'one', 'another'] - [and] vs [.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2003/50000 [01:17<31:02, 25.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 2000, Average loss= 3.541041, Average Accuracy= 17.50%\n",
      "['got', 'up', 'and'] - [said] vs [round]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3001/50000 [01:57<30:37, 25.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 3000, Average loss= 3.141578, Average Accuracy= 24.40%\n",
      "[',', 'and', 'could'] - [easily] vs [said]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4001/50000 [02:42<31:08, 24.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 4000, Average loss= 3.092450, Average Accuracy= 30.70%\n",
      "['neck', 'of', 'the'] - [cat] vs [i]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5002/50000 [03:26<30:54, 24.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 5000, Average loss= 2.261444, Average Accuracy= 43.60%\n",
      "['we', 'could', 'easily'] - [escape] vs [to]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6002/50000 [04:09<30:26, 24.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 6000, Average loss= 2.582534, Average Accuracy= 40.50%\n",
      "['of', 'her', 'approach'] - [,] vs [,]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7004/50000 [04:52<29:54, 23.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 7000, Average loss= 2.445378, Average Accuracy= 42.80%\n",
      "['us', '.', 'now'] - [,] vs [the]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8004/50000 [05:35<29:20, 23.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 8000, Average loss= 1.973058, Average Accuracy= 49.90%\n",
      "['in', 'which', 'the'] - [enemy] vs [enemy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9003/50000 [06:18<28:44, 23.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 9000, Average loss= 1.758262, Average Accuracy= 56.70%\n",
      "['agree', ',', 'said'] - [he] vs [he]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10003/50000 [07:01<28:06, 23.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 10000, Average loss= 1.580687, Average Accuracy= 60.90%\n",
      "['and', 'said', 'he'] - [had] vs [is]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11002/50000 [07:39<27:08, 23.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 11000, Average loss= 1.347442, Average Accuracy= 65.70%\n",
      "['to', 'outwit', 'their'] - [common] vs [common]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12003/50000 [08:14<26:04, 24.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 12000, Average loss= 1.335453, Average Accuracy= 68.10%\n",
      "['another', 'and', 'nobody'] - [spoke] vs [of]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13005/50000 [08:49<25:05, 24.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 13000, Average loss= 1.427956, Average Accuracy= 64.20%\n",
      "['and', 'said', 'that'] - [is] vs [is]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14002/50000 [09:23<24:09, 24.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 14000, Average loss= 1.460478, Average Accuracy= 66.20%\n",
      "['applause', ',', 'until'] - [an] vs [of]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15003/50000 [09:58<23:15, 25.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 15000, Average loss= 1.195041, Average Accuracy= 70.60%\n",
      "['the', 'neighbourhood', '.'] - [this] vs [this]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16004/50000 [10:33<22:24, 25.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 16000, Average loss= 1.231290, Average Accuracy= 70.60%\n",
      "['cat', '.', 'by'] - [this] vs [this]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17001/50000 [11:13<21:46, 25.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 17000, Average loss= 1.207707, Average Accuracy= 71.10%\n",
      "['the', 'neck', 'of'] - [the] vs [the]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18001/50000 [11:56<21:14, 25.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 18000, Average loss= 1.258300, Average Accuracy= 70.50%\n",
      "[',', 'to', 'propose'] - [that] vs [that]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19003/50000 [12:39<20:39, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 19000, Average loss= 1.051942, Average Accuracy= 74.20%\n",
      "['her', 'approach', ','] - [we] vs [said]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20001/50000 [13:23<20:05, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 20000, Average loss= 0.766569, Average Accuracy= 81.10%\n",
      "['that', 'our', 'chief'] - [danger] vs [danger]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21002/50000 [14:02<19:23, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 21000, Average loss= 0.748996, Average Accuracy= 81.90%\n",
      "['case', '.', 'you'] - [will] vs [,]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22004/50000 [14:39<18:39, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 22000, Average loss= 1.057588, Average Accuracy= 78.00%\n",
      "['had', 'a', 'proposal'] - [to] vs [council]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23004/50000 [15:19<17:58, 25.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 23000, Average loss= 0.806153, Average Accuracy= 79.90%\n",
      "['could', 'take', 'to'] - [outwit] vs [outwit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24003/50000 [15:56<17:15, 25.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 24000, Average loss= 0.719810, Average Accuracy= 81.60%\n",
      "['to', 'bell', 'the'] - [cat] vs [cat]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25002/50000 [16:34<16:34, 25.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 25000, Average loss= 0.892054, Average Accuracy= 80.30%\n",
      "['well', ',', 'but'] - [who] vs [could]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26002/50000 [17:17<15:57, 25.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 26000, Average loss= 0.944023, Average Accuracy= 79.10%\n",
      "['until', 'an', 'old'] - [mouse] vs [was]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27000/50000 [17:59<15:19, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 27000, Average loss= 0.825691, Average Accuracy= 81.70%\n",
      "['retire', 'while', 'she'] - [was] vs [was]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28004/50000 [18:45<14:43, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 28000, Average loss= 0.641051, Average Accuracy= 85.60%\n",
      "['the', 'neck', 'of'] - [the] vs [the]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29003/50000 [19:27<14:05, 24.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 29000, Average loss= 0.704618, Average Accuracy= 84.20%\n",
      "['i', 'venture', ','] - [therefore] vs [and]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30003/50000 [20:10<13:27, 24.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 30000, Average loss= 0.659248, Average Accuracy= 85.90%\n",
      "['receive', 'some', 'signal'] - [of] vs [always]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31003/50000 [20:54<12:48, 24.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 31000, Average loss= 0.934160, Average Accuracy= 80.10%\n",
      "['enemy', 'approaches', 'us'] - [.] vs [.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32002/50000 [21:38<12:10, 24.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 32000, Average loss= 0.701973, Average Accuracy= 85.20%\n",
      "['said', 'he', ','] - [that] vs [that]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33004/50000 [22:16<11:28, 24.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 33000, Average loss= 0.760093, Average Accuracy= 84.00%\n",
      "['thought', 'would', 'meet'] - [the] vs [the]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34003/50000 [22:56<10:47, 24.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 34000, Average loss= 0.626493, Average Accuracy= 85.50%\n",
      "['this', ',', 'and'] - [some] vs [some]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35002/50000 [23:35<10:06, 24.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 35000, Average loss= 0.712144, Average Accuracy= 84.20%\n",
      "['what', 'measures', 'they'] - [could] vs [they]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36001/50000 [24:17<09:26, 24.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 36000, Average loss= 0.722714, Average Accuracy= 84.70%\n",
      "['to', 'consider', 'what'] - [measures] vs [common]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37002/50000 [25:01<08:47, 24.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 37000, Average loss= 0.732080, Average Accuracy= 84.60%\n",
      "['general', 'council', 'to'] - [consider] vs [consider]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38001/50000 [25:45<08:07, 24.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 38000, Average loss= 0.721269, Average Accuracy= 84.20%\n",
      "['it', 'is', 'easy'] - [to] vs [to]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39001/50000 [26:29<07:28, 24.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 39000, Average loss= 0.642090, Average Accuracy= 86.50%\n",
      "['mice', 'looked', 'at'] - [one] vs [one]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40001/50000 [27:13<06:48, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 40000, Average loss= 0.787285, Average Accuracy= 82.80%\n",
      "['is', 'all', 'very'] - [well] vs [well]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41003/50000 [27:55<06:07, 24.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 41000, Average loss= 0.587612, Average Accuracy= 87.80%\n",
      "['in', 'the', 'neighbourhood'] - [.] vs [.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42003/50000 [28:39<05:27, 24.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 42000, Average loss= 0.589213, Average Accuracy= 86.80%\n",
      "['ribbon', 'round', 'the'] - [neck] vs [neck]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43003/50000 [29:16<04:45, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 43000, Average loss= 0.642746, Average Accuracy= 86.80%\n",
      "['therefore', ',', 'to'] - [propose] vs [attached]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44003/50000 [29:56<04:04, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 44000, Average loss= 0.743872, Average Accuracy= 84.20%\n",
      "['her', 'approach', ','] - [we] vs [we]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45002/50000 [30:39<03:24, 24.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 45000, Average loss= 0.543556, Average Accuracy= 88.10%\n",
      "['the', 'enemy', 'approaches'] - [us] vs [us]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46001/50000 [31:23<02:43, 24.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 46000, Average loss= 0.712971, Average Accuracy= 85.30%\n",
      "['in', 'the', 'sly'] - [and] vs [and]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47003/50000 [32:07<02:02, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 47000, Average loss= 0.657937, Average Accuracy= 85.80%\n",
      "['proposal', 'to', 'make'] - [,] vs [,]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48001/50000 [32:50<01:22, 24.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 48000, Average loss= 0.552095, Average Accuracy= 86.90%\n",
      "[',', 'and', 'some'] - [said] vs [said]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49001/50000 [33:35<00:41, 24.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 49000, Average loss= 0.606203, Average Accuracy= 86.90%\n",
      "['council', 'to', 'consider'] - [what] vs [their]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [34:11<00:00, 24.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 50000, Average loss= 0.527941, Average Accuracy= 87.00%\n",
      "['said', 'it', 'is'] - [easy] vs [easy]\n",
      "Optimization Finished!\n",
      "Elapsed time:  34.49983052810033 min\n",
      "Run on command line.\n",
      "\ttensorboard --logdir=tensorflow/logs\n",
      "Point your web browser to: http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "# This code will train 50k iters, if session is saved already dont run, instead run the next block of code\n",
    "from tqdm import tqdm as tqdm\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    offset = random.randint(0, n_input+1)\n",
    "    end_offset = n_input+1\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "    \n",
    "    writer.add_graph(session.graph)\n",
    "    for step in tqdm(range(training_iters)):\n",
    "        if offset > (len(training_data)-end_offset):\n",
    "            offset = random.randint(0, n_input+1)\n",
    "        symbols_in_keys = [ [dictionary[str(training_data[i])]] for i in range(offset, offset+n_input)]\n",
    "        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "        \n",
    "        symbols_out_onehot = np.zeros([vocab_size], dtype = float)\n",
    "        symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n",
    "        symbols_out_onehot = np.reshape(symbols_out_onehot, [1, -1])\n",
    "        \n",
    "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
    "                                               feed_dict = {x: symbols_in_keys, y: symbols_out_onehot})\n",
    "    \n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        if (step+1)%display_step == 0:\n",
    "            print(\"Iter= \" + str(step+1) + \", Average loss= \" + \\\n",
    "                 \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
    "                 \"{:.2f}%\".format(100*acc_total/display_step))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            symbols_in = [training_data[i] for i in range(offset, offset+n_input)]\n",
    "            symbols_out = training_data[offset+n_input]\n",
    "            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (symbols_in, symbols_out, symbols_out_pred))\n",
    "        offset += (n_input+1)\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(session, \"./sessions/model.ckpt\")\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Elapsed time: \", elapsed(time.time() - start_time))\n",
    "    print(\"Run on command line.\")\n",
    "    print(\"\\ttensorboard --logdir=%s\" % (log_path))\n",
    "    print(\"Point your web browser to: http://localhost:6006/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./sessions/model.ckpt\n",
      "3 words: council to consider\n",
      "council to consider their measures could take mouse\n",
      "3 words: proposal to make\n",
      "proposal to make , which he thought would\n",
      "3 words: got up and\n",
      "got up and said that is all very\n",
      "3 words: mice looked at\n",
      "mice looked at one another . then the\n",
      "3 words: in the background\n",
      "Word not in the dictionary!\n",
      "3 words: in the backgroun\n",
      "Word not in the dictionary!\n",
      "3 words: in the\n",
      "3 words: ok\n",
      "3 words: her approach ,\n",
      "her approach , and could easily retire while\n",
      "3 words: ok google here\n",
      "Word not in the dictionary!\n",
      "3 words: what measures they\n",
      "what measures they could take mouse got up\n",
      "3 words: exit\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, \"./sessions/model.ckpt\")\n",
    "    while True:\n",
    "        prompt = \"%s words: \" % n_input\n",
    "        sentence = input(prompt)\n",
    "        if sentence == \"exit\":\n",
    "            break\n",
    "        sentence = sentence.strip()\n",
    "        words = sentence.split(' ')\n",
    "        if len(words) != n_input:\n",
    "            continue\n",
    "        try:\n",
    "            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
    "            for i in range(5):\n",
    "                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "                onehot_pred = session.run(pred, feed_dict={x: keys})\n",
    "                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n",
    "                sentence = \"%s %s\" % (sentence, reverse_dictionary[onehot_pred_index])\n",
    "                symbols_in_keys = symbols_in_keys[1:]\n",
    "                symbols_in_keys.append(onehot_pred_index)\n",
    "            print(sentence)\n",
    "        except:\n",
    "            print(\"Word not in the dictionary!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
